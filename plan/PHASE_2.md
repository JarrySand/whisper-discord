# ğŸ™ï¸ Phase 2: Whisper API ã‚µãƒ¼ãƒãƒ¼

> **ç›®æ¨™**: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å—ã‘å–ã‚Šã€Whisper ã§æ–‡å­—èµ·ã“ã—ã‚’è¡Œã† HTTP API ã‚µãƒ¼ãƒãƒ¼ã‚’æ§‹ç¯‰
>
> **æœŸé–“ç›®å®‰**: 2-3æ—¥
>
> **ä»•æ§˜æ›¸**: [03-whisper-api.md](../docs/details/03-whisper-api.md)

---

## ğŸ“‹ ã‚¿ã‚¹ã‚¯ä¸€è¦§

### 2.1 ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆæœŸåŒ– (Day 1)

#### ã‚¿ã‚¹ã‚¯

- [x] **T-2.1.1**: whisper-api ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
- [x] **T-2.1.2**: requirements.txt ä½œæˆ
- [x] **T-2.1.3**: ç’°å¢ƒå¤‰æ•°è¨­å®š (.env.example, .env)
- [x] **T-2.1.4**: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆ
- [x] **T-2.1.5**: ãƒ­ã‚°è¨­å®š

#### æˆæœç‰©

```
whisper-api/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ routes.py
â”‚   â”‚   â””â”€â”€ schemas.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â””â”€â”€ logging.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ whisper.py
â”‚   â”‚   â””â”€â”€ audio.py
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ __init__.py
â”œâ”€â”€ models/               # Whisperãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥
â”œâ”€â”€ temp/                 # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ .env
```

#### ä¾å­˜é–¢ä¿‚

```
# requirements.txt
fastapi==0.109.0
uvicorn[standard]==0.25.0
python-multipart==0.0.6
pydantic==2.5.3
pydantic-settings==2.1.0

# Whisper
faster-whisper==1.0.0
torch>=2.0.0
torchaudio>=2.0.0

# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
python-dotenv==1.0.0
```

```
# requirements-dev.txt (ãƒ†ã‚¹ãƒˆç”¨)
pytest==7.4.3
pytest-cov==4.1.0
pytest-asyncio==0.21.1
httpx==0.25.2
```

---

### 2.2 FastAPI åŸºç›¤ (Day 1)

#### ã‚¿ã‚¹ã‚¯

- [x] **T-2.2.1**: FastAPI ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ä½œæˆ
- [x] **T-2.2.2**: è¨­å®šç®¡ç† (pydantic-settings)
- [x] **T-2.2.3**: CORS è¨­å®š
- [x] **T-2.2.4**: Lifespan ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆèµ·å‹•/çµ‚äº†ï¼‰
- [x] **T-2.2.5**: ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

#### å®Ÿè£…ãƒã‚¤ãƒ³ãƒˆ

```python
# main.py
@asynccontextmanager
async def lifespan(app: FastAPI):
    # èµ·å‹•æ™‚: ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
    whisper_service.load_model()
    yield
    # çµ‚äº†æ™‚: ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

app = FastAPI(lifespan=lifespan)
```

#### æ¤œè¨¼é …ç›®

- [x] `uvicorn src.main:app --reload` ã§èµ·å‹•
- [x] `GET /health` ãŒ `200 OK` ã‚’è¿”ã™
- [x] Swagger UI (`/docs`) ã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½

---

### 2.3 Pydantic ã‚¹ã‚­ãƒ¼ãƒ (Day 1)

#### ã‚¿ã‚¹ã‚¯

- [x] **T-2.3.1**: TranscribeRequest ã‚¹ã‚­ãƒ¼ãƒ
- [x] **T-2.3.2**: TranscriptionResult ã‚¹ã‚­ãƒ¼ãƒ
- [x] **T-2.3.3**: TranscribeResponse ã‚¹ã‚­ãƒ¼ãƒ
- [x] **T-2.3.4**: HealthResponse ã‚¹ã‚­ãƒ¼ãƒ
- [x] **T-2.3.5**: ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¹ã‚­ãƒ¼ãƒ

#### ã‚¹ã‚­ãƒ¼ãƒä¾‹

```python
class TranscriptionResult(BaseModel):
    user_id: str
    username: str
    display_name: Optional[str]
    text: str
    start_ts: int
    end_ts: int
    duration_ms: int
    language: str
    confidence: float
    processing_time_ms: int
```

---

### 2.4 Whisper ã‚µãƒ¼ãƒ“ã‚¹ (Day 2)

#### ã‚¿ã‚¹ã‚¯

- [x] **T-2.4.1**: WhisperService ã‚¯ãƒ©ã‚¹ä½œæˆ
- [x] **T-2.4.2**: ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å‡¦ç†
- [x] **T-2.4.3**: transcribe ãƒ¡ã‚½ãƒƒãƒ‰å®Ÿè£…
- [x] **T-2.4.4**: ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—
- [x] **T-2.4.5**: çµ±è¨ˆæƒ…å ±åé›†

#### å®Ÿè£…ãƒã‚¤ãƒ³ãƒˆ

```python
class WhisperService:
    def __init__(self, config: WhisperConfig):
        self.model = WhisperModel(
            model_size_or_path=config.model_name,
            device=config.device,
            compute_type=config.compute_type,
        )

    def transcribe(self, audio_path: str, language: str = "ja"):
        segments, info = self.model.transcribe(
            audio_path,
            language=language,
            beam_size=5,
            vad_filter=True,
        )
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆçµåˆ â†’ ãƒ†ã‚­ã‚¹ãƒˆè¿”å´
```

#### Whisper è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³

| è¨­å®š | CPUæ¨å¥¨ | GPUæ¨å¥¨ |
|------|---------|---------|
| model_name | large-v3 | large-v3 |
| device | cpu | cuda |
| compute_type | int8 | float16 |
| beam_size | 1 | 5 |

---

### 2.5 æ–‡å­—èµ·ã“ã—ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ (Day 2-3)

#### ã‚¿ã‚¹ã‚¯

- [x] **T-2.5.1**: POST `/transcribe` å®Ÿè£…
- [x] **T-2.5.2**: ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†
- [x] **T-2.5.3**: ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†
- [x] **T-2.5.4**: å…¥åŠ›ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
- [x] **T-2.5.5**: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

#### ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆä»•æ§˜

```
POST /transcribe
Content-Type: multipart/form-data

Parameters:
  - audio_file: File (required)
  - user_id: string (required)
  - username: string (required)
  - display_name: string (optional)
  - start_ts: int (required)
  - end_ts: int (required)
  - language: string (default: "ja")

Response:
{
  "success": true,
  "data": {
    "text": "æ–‡å­—èµ·ã“ã—çµæœ",
    "confidence": 0.95,
    ...
  }
}
```

#### æ¤œè¨¼é …ç›®

- [x] OGG ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸ
- [x] WAV ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸ
- [x] æ—¥æœ¬èªã®æ–‡å­—èµ·ã“ã—ãŒæ­£ç¢º
- [x] ã‚¨ãƒ©ãƒ¼æ™‚ã«é©åˆ‡ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹

---

### 2.6 ãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ (Day 3, ã‚ªãƒ—ã‚·ãƒ§ãƒ³)

#### ã‚¿ã‚¹ã‚¯

- [x] **T-2.6.1**: POST `/transcribe/batch` å®Ÿè£…
- [x] **T-2.6.2**: è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«å—ä¿¡å‡¦ç†
- [x] **T-2.6.3**: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿é…åˆ—è§£æ
- [x] **T-2.6.4**: ä¸¦åˆ—/ç›´åˆ—å‡¦ç†é¸æŠ

#### ãƒãƒƒãƒä»•æ§˜

```
POST /transcribe/batch
Content-Type: multipart/form-data

Parameters:
  - files: File[] (required)
  - metadata: JSON string (required)
```

---

### 2.7 ãƒ‡ãƒã‚¤ã‚¹æ¤œå‡ºãƒ»æœ€é©åŒ– (Day 3)

#### ã‚¿ã‚¹ã‚¯

- [x] **T-2.7.1**: GPU æ¤œå‡ºãƒ­ã‚¸ãƒƒã‚¯
- [x] **T-2.7.2**: è¨ˆç®—ç²¾åº¦è‡ªå‹•é¸æŠ
- [x] **T-2.7.3**: CPU æœ€é©åŒ–è¨­å®š

#### ãƒ‡ãƒã‚¤ã‚¹æ¤œå‡º

```python
def detect_device() -> str:
    if torch.cuda.is_available():
        return "cuda"
    elif hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
        return "mps"  # Apple Silicon
    else:
        return "cpu"
```

---

## ğŸ§ª Phase 2 å®Œäº†ãƒ†ã‚¹ãƒˆ

### å˜ä½“ãƒ†ã‚¹ãƒˆ

```python
# tests/test_whisper_service.py
def test_transcribe_japanese():
    service = WhisperService(config)
    text, confidence = service.transcribe("sample.ogg", "ja")
    assert len(text) > 0
    assert confidence > 0.5
```

### API ãƒ†ã‚¹ãƒˆ

```python
# tests/test_routes.py
def test_transcribe_endpoint(client, sample_audio):
    response = client.post(
        "/transcribe",
        files={"audio_file": sample_audio},
        data={"user_id": "123", "username": "test", ...}
    )
    assert response.status_code == 200
    assert response.json()["success"] is True
```

### æ‰‹å‹•ãƒ†ã‚¹ãƒˆ

```bash
# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
curl http://localhost:8000/health

# æ–‡å­—èµ·ã“ã—
curl -X POST http://localhost:8000/transcribe \
  -F "audio_file=@sample.ogg" \
  -F "user_id=123" \
  -F "username=test" \
  -F "start_ts=1733389200000" \
  -F "end_ts=1733389205000"
```

---

## ğŸ“ æˆæœç‰©ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 

```
whisper-api/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py               # FastAPI ã‚¢ãƒ—ãƒª
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ routes.py         # ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
â”‚   â”‚   â””â”€â”€ schemas.py        # Pydantic ãƒ¢ãƒ‡ãƒ«
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py         # è¨­å®šç®¡ç†
â”‚   â”‚   â””â”€â”€ logging.py        # ãƒ­ã‚°è¨­å®š
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ whisper.py        # Whisperæ¨è«–
â”‚   â”‚   â””â”€â”€ audio.py          # éŸ³å£°å‰å‡¦ç†
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ __init__.py
â”œâ”€â”€ models/                   # ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥
â”œâ”€â”€ temp/                     # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ test_routes.py
â”‚   â””â”€â”€ test_whisper_service.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ .env
```

---

## âš ï¸ æ³¨æ„äº‹é …

### ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

åˆå›èµ·å‹•æ™‚ã« Whisper ãƒ¢ãƒ‡ãƒ«ï¼ˆç´„3GBï¼‰ãŒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™ã€‚

```bash
# äº‹å‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
python -c "from faster_whisper import WhisperModel; WhisperModel('large-v3')"
```

### ãƒ¡ãƒ¢ãƒªè¦ä»¶

| ãƒ¢ãƒ‡ãƒ« | VRAM/RAM |
|--------|----------|
| tiny | 1GB |
| base | 1GB |
| small | 2GB |
| medium | 5GB |
| large-v3 | 10GB |

### GPU ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

```bash
# CUDA 11.x
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.x
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›®å®‰

| ç’°å¢ƒ | 1åˆ†éŸ³å£°ã®å‡¦ç†æ™‚é–“ |
|------|------------------|
| CPU (int8) | 30-60ç§’ |
| GPU (float16) | 5-10ç§’ |

---

## ğŸ³ Docker å¯¾å¿œï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

```dockerfile
# Dockerfile
FROM python:3.10-slim

WORKDIR /app
RUN apt-get update && apt-get install -y ffmpeg

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY src/ ./src/
RUN mkdir -p /app/models /app/temp

EXPOSE 8000
CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

---

**æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—**: [Phase 3 - çµåˆ](./PHASE_3.md)

